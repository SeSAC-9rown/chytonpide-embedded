import os
import azure.cognitiveservices.speech as speechsdk
from dotenv import load_dotenv
import pygame

load_dotenv()

class AzureTTS:
    def __init__(self):
        self.speech_key = os.getenv("AZURE_SPEECH_KEY")
        self.service_region = os.getenv("AZURE_SPEECH_REGION")
        
        if not self.speech_key or not self.service_region:
            raise ValueError("âŒ .env íŒŒì¼ í™•ì¸ í•„ìš”")

        pygame.mixer.init()

        # Speech ConfigëŠ” í•œ ë²ˆë§Œ ë¡œë“œí•´ì„œ ì¬ì‚¬ìš© (ì†ë„ í–¥ìƒ)
        self.speech_config = speechsdk.SpeechConfig(subscription=self.speech_key, region=self.service_region)
        self.speech_config.set_speech_synthesis_output_format(
            speechsdk.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3
        )
        self.speech_config.speech_recognition_language = "ko-KR"

    def speak(self, text, params):
        print(f"ğŸ”Š [TTS] ìŒì„± ìƒì„± ì‹œì‘: {text[:15]}...", end=" ", flush=True)
        
        voice = params.get("voice", "ko-KR-SeoHyeonNeural")
        style = params.get("style", "cheerful")
        degree = params.get("style_degree", 2.0)
        pitch = params.get("pitch", 0)
        rate = params.get("rate", 0)

        ssml_string = (
            f'<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="ko-KR">'
            f'<voice name="{voice}">'
            f'<mstts:express-as style="{style}" styledegree="{degree}">'
            f'<prosody pitch="{pitch:+d}%" rate="{rate:+d}%">'
            f'{text}'
            f'</prosody></mstts:express-as></voice></speak>'
        )

        current_dir = os.path.dirname(os.path.abspath(__file__))
        temp_filename = os.path.join(current_dir, "temp_output.mp3")

        # íŒŒì¼ ì €ì¥ìš© í•©ì„±ê¸° ìƒì„±
        synthesizer = speechsdk.SpeechSynthesizer(speech_config=self.speech_config, audio_config=None)
        
        # ë¹„ë™ê¸° ì‹¤í–‰ (ìƒì„±)
        result = synthesizer.speak_ssml_async(ssml_string).get()

        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            print("âœ… ìƒì„± ì™„ë£Œ -> ì¬ìƒ ì¤‘", flush=True)
            
            # íŒŒì¼ ì“°ê¸°
            with open(temp_filename, "wb") as f:
                f.write(result.audio_data)
            
            # ì¬ìƒ
            try:
                pygame.mixer.music.load(temp_filename)
                pygame.mixer.music.play()
                while pygame.mixer.music.get_busy():
                    pygame.time.Clock().tick(30) # ì²´í¬ ì£¼ê¸°ë¥¼ 10->30ìœ¼ë¡œ ë†’ì—¬ ë°˜ì‘ì„± í–¥ìƒ
                pygame.mixer.music.unload()
            except Exception as e:
                print(f"\nâŒ ì¬ìƒ ì˜¤ë¥˜: {e}")

            # íŒŒì¼ ì‚­ì œ (ë¹ ë¥¸ ì •ë¦¬ë¥¼ ìœ„í•´ try-except ìµœì†Œí™”)
            try: os.remove(temp_filename)
            except: pass

        elif result.reason == speechsdk.ResultReason.Canceled:
            print(f"\nâŒ [TTS ì‹¤íŒ¨] {result.cancellation_details.error_details}")

        del synthesizer

    def listen(self):
        # ë“£ê¸° ì „ìš© ì„¤ì •
        audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
        recognizer = speechsdk.SpeechRecognizer(speech_config=self.speech_config, audio_config=audio_config)

        # [ì¤‘ìš”] ì¹¨ë¬µ ê°ì§€ ì‹œê°„ ë‹¨ì¶• (ë§ ëë‚˜ë©´ ë” ë¹¨ë¦¬ ì¸ì‹í•˜ë„ë¡)
        # ê¸°ë³¸ê°’ë³´ë‹¤ ì§§ê²Œ ì„¤ì •í•˜ì—¬ ë°˜ì‘ ì†ë„ë¥¼ ë†’ì„
        # InitialSilenceTimeout: ë§ ì‹œì‘ ì „ ëŒ€ê¸° ì‹œê°„
        # EndSilenceTimeout: ë§ ëë‚œ í›„ ëŒ€ê¸° ì‹œê°„ (ì´ê±¸ ì¤„ì—¬ì•¼ ë¹¨ë¦¬ ë„˜ì–´ê°)
        recognizer.properties.set_property_by_name("SpeechServiceConnection_InitialSilenceTimeoutMs", "3000")
        recognizer.properties.set_property_by_name("Speech_SegmentationSilenceTimeoutMs", "1000")

        print("\nğŸ‘‚ ë“£ëŠ” ì¤‘...", end=" ", flush=True)
        
        result = recognizer.recognize_once_async().get()

        # ë¦¬ì†ŒìŠ¤ ì¦‰ì‹œ í•´ì œ (ì¶©ëŒ ë°©ì§€)
        del recognizer
        del audio_config

        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            print(f"âœ… ì¸ì‹ë¨: \"{result.text}\"", flush=True)
            return result.text
        elif result.reason == speechsdk.ResultReason.NoMatch:
            print("ğŸ”• (ì¹¨ë¬µ)", flush=True)
            return None
        elif result.reason == speechsdk.ResultReason.Canceled:
            print("âŒ (ì·¨ì†Œ/ì˜¤ë¥˜)", flush=True)
            return None