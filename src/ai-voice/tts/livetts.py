import os
import time
import azure.cognitiveservices.speech as speechsdk
from dotenv import load_dotenv
import pygame

load_dotenv()

class AzureTTS:
    def __init__(self):
        self.speech_key = os.getenv("AZURE_SPEECH_KEY")
        self.service_region = os.getenv("AZURE_SPEECH_REGION")
        
        if not self.speech_key or not self.service_region:
            print("âŒ ì˜¤ë¥˜: .env íŒŒì¼ì´ ì—†ê±°ë‚˜ í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            raise ValueError(".env íŒŒì¼ í™•ì¸ í•„ìš”")

        # Pygame ì´ˆê¸°í™” (ì˜¤ë””ì˜¤ ì¬ìƒìš©)
        pygame.mixer.init()

        self.speech_config = speechsdk.SpeechConfig(subscription=self.speech_key, region=self.service_region)
        # ê³ ìŒì§ˆ ì„¤ì • (48kHz)
        self.speech_config.set_speech_synthesis_output_format(
            speechsdk.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3
        )

    def speak(self, text, params):
        # 1. ì‚¬ìš©ì ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
        voice = params.get("voice", "ko-KR-SeoHyeonNeural")
        style = params.get("style", "cheerful")
        degree = params.get("style_degree", 1.0)
        pitch = params.get("pitch", 0)
        rate = params.get("rate", 0)

        # 2. SSML í¬ë§·íŒ… (+ ë¶€í˜¸ ë¶™ì´ê¸°)
        fmt_pitch = f"+{pitch}%" if pitch >= 0 else f"{pitch}%"
        fmt_rate = f"+{rate}%" if rate >= 0 else f"{rate}%"

        # 3. SSML ìƒì„± (ì‚¬ìš©ì ì„¤ì • ì ìš©)
        ssml_string = (
            f'<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="ko-KR">'
            f'<voice name="{voice}">'
            f'<mstts:express-as style="{style}" styledegree="{degree}">'
            f'<prosody pitch="{fmt_pitch}" rate="{fmt_rate}">'
            f'{text}'
            f'</prosody></mstts:express-as></voice></speak>'
        )

        # ì ˆëŒ€ ê²½ë¡œë¡œ íŒŒì¼ëª… ì„¤ì •
        current_dir = os.path.dirname(os.path.abspath(__file__))
        temp_filename = os.path.join(current_dir, "temp_output.mp3")

        # 4. Azure í•©ì„±ê¸° ìƒì„± (ìŠ¤í”¼ì»¤ ì‚¬ìš© X -> ë°ì´í„°ë§Œ ë°›ìŒ)
        synthesizer = speechsdk.SpeechSynthesizer(speech_config=self.speech_config, audio_config=None)

        print(f"ğŸ”Š ì¹˜í”¼ ìƒì„± ì¤‘... (Pitch:{fmt_pitch}, Rate:{fmt_rate})")
        
        # 5. ì‹¤í–‰
        result = synthesizer.speak_ssml_async(ssml_string).get()

        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            # 6. ë°›ì€ ë°ì´í„°ë¥¼ ì§ì ‘ íŒŒì¼ë¡œ ì €ì¥ (ì˜¤ë¥˜ ì›ì²œ ì°¨ë‹¨)
            audio_data = result.audio_data
            with open(temp_filename, "wb") as f:
                f.write(audio_data)
            
            # 7. Pygameìœ¼ë¡œ ì¬ìƒ
            try:
                pygame.mixer.music.load(temp_filename)
                pygame.mixer.music.play()
                while pygame.mixer.music.get_busy():
                    pygame.time.Clock().tick(10)
                pygame.mixer.music.unload()
            except Exception as e:
                print(f"âŒ ì¬ìƒ ì˜¤ë¥˜: {e}")

            # íŒŒì¼ ì •ë¦¬
            try:
                if os.path.exists(temp_filename):
                    os.remove(temp_filename)
            except:
                pass

        elif result.reason == speechsdk.ResultReason.Canceled:
            details = result.cancellation_details
            print(f"âŒ [Azure ì˜¤ë¥˜] {details.error_details}")

        del synthesizer

# =========================================================
# 2. ë“£ê¸° ë‹´ë‹¹ (STT)
# =========================================================
def listen_to_user():
    speech_key = os.getenv("AZURE_SPEECH_KEY")
    service_region = os.getenv("AZURE_SPEECH_REGION")
    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
    speech_config.speech_recognition_language = "ko-KR" 
    
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    
    print("\nğŸ¤ ë“£ê³  ìˆì–´ìš”... (ë§ì”€í•´ ë³´ì„¸ìš”)")
    result = recognizer.recognize_once_async().get()
    
    # ë¦¬ì†ŒìŠ¤ í•´ì œ
    del recognizer
    del audio_config
    
    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        print(f"ğŸ“ ì¸ì‹: {result.text}")
        return result.text
    return None

# =========================================================
# 3. LLM ë¡œì§ (ê°€ì§œ)
# =========================================================
def get_ai_response(user_text):
    if "ì•ˆë…•" in user_text: return "ì•ˆë…• ê³ ì–‘ì´ë°”ì§ˆê¾¼! ë°˜ê°€ì›Œ! ì˜¤ëŠ˜ë„ ë°”ì§ˆ ë³´ëŸ¬ ì™”ì–´?"
    elif "ìƒíƒœ" in user_text: return "ìŒ... ë°”ì§ˆ ìì´ ì¡°ê¸ˆ ì‹œë¬´ë£©í•´ ë³´ì—¬. ë¬¼ì„ ì¢€ ì£¼ë©´ ì–´ë•Œ?"
    elif "ì¢…ë£Œ" in user_text: return "exit"
    return f"ë„¤ê°€ ë°©ê¸ˆ '{user_text}'ë¼ê³  ë§í–ˆì§€? ë‚´ê°€ ë˜‘ê°™ì´ ë§í•´ì¤„ê²Œ!"

# =========================================================
# 4. ì‹¤í–‰
# =========================================================
if __name__ == "__main__":
    try:
        tts = AzureTTS()
        
        # âœ¨ [ì‚¬ìš©ìë‹˜ ì„¤ì •ê°’ ì ìš© ì™„ë£Œ]
        chipi_params = {
            "voice": "ko-KR-SeoHyeonNeural",  # ì„œí˜„ì´
            "style": "cheerful",              # ì¾Œí™œí•¨
            "style_degree": 1.0,              # ê°•ë„ 1.0
            "pitch": 20,                      # í”¼ì¹˜ +20% (ë†’ìŒ)
            "rate": 20                        # ì†ë„ +20% (ë¹ ë¦„)
        }
        
        print("============== ì¹˜í”¼ ìŒì„± ë¹„ì„œ ì‹œì‘ ==============")
        tts.speak("ì¹˜í”¼ê°€ ê¹¨ì–´ë‚¬ì–´! ë‚˜ë‘ ëŒ€í™”í•˜ì!", chipi_params)

        while True:
            text = listen_to_user()
            if not text: continue
            
            response = get_ai_response(text)
            if response == "exit": 
                tts.speak("ì•Œê² ì–´! ë‚˜ì¤‘ì— ë˜ ë´! ì•ˆë…•!", chipi_params)
                break
            
            print(f"ğŸ¤– ì¹˜í”¼ ìƒê°: {response}")
            tts.speak(response, chipi_params)
            
    except Exception as e:
        print(f"Error: {e}")